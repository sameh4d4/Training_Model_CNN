{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import InceptionV3, VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ],
   "id": "1e807385d9a4ed38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "root_path=\"data/\"\n",
    "ngantuk_path=root_path+\"/ngantuk/wajah\"\n",
    "sadar_path=root_path+\"/sadar/wajah\"\n",
    "chekpoints_path = \"Model CNN/no patience/Checkpoint\"\n",
    "model_path= \"Model CNN/no patience\""
   ],
   "id": "7480e857d7207782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# insert all image in dataset folder to list\n",
    "ngantuks = []\n",
    "sadars = []\n",
    "for filename in os.listdir(ngantuk_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "      image = cv2.imread(os.path.join(ngantuk_path, filename))\n",
    "      ngantuks.append(image)\n",
    "      print(filename)\n",
    "\n",
    "for filename in os.listdir(sadar_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "      image = cv2.imread(os.path.join(sadar_path, filename))\n",
    "      sadars.append(image)\n",
    "      print(filename)"
   ],
   "id": "41272af9f13f6789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# preparing image",
   "id": "130c08a8401fbafb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rotates=[cv2.ROTATE_90_CLOCKWISE,cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "# resize and input data, and target\n",
    "img_size=200\n",
    "data=[]\n",
    "hitung=0\n",
    "target=[]\n",
    "for img1 in ngantuks:\n",
    "  img=img1.copy()\n",
    "  try:\n",
    "    resized=cv2.resize(img,(img_size,img_size))\n",
    "    rotated=cv2.rotate(resized,rotates[random.randint(0,1)])\n",
    "    fliped=cv2.flip(resized,random.randint(0,1))\n",
    "    data.append(resized)\n",
    "    target.append(\"ngantuk\")\n",
    "    hitung+=1\n",
    "    data.append(rotated)\n",
    "    target.append(\"ngantuk\")\n",
    "    hitung+=1\n",
    "    data.append(fliped)\n",
    "    target.append(\"ngantuk\")\n",
    "    hitung+=1\n",
    "  except Exception as e:\n",
    "    print('Exception:',e)\n",
    "\n",
    "for img1 in sadars:\n",
    "  try:\n",
    "    img=img1.copy()\n",
    "    resized=cv2.resize(img,(img_size,img_size))\n",
    "    rotated=cv2.rotate(resized,rotates[random.randint(0,1)])\n",
    "    fliped=cv2.flip(resized,random.randint(0,1))\n",
    "    data.append(resized)\n",
    "    target.append(\"sadar\")\n",
    "    hitung+=1\n",
    "    data.append(rotated)\n",
    "    target.append(\"sadar\")\n",
    "    hitung+=1\n",
    "    data.append(fliped)\n",
    "    target.append(\"sadar\")\n",
    "    hitung+=1\n",
    "  except Exception as e:\n",
    "    print('Exception:',e)\n",
    "\n",
    "print(str(len(ngantuks)+len(sadars)))\n",
    "print(str(hitung))"
   ],
   "id": "964bcd6700bfdc00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# encode kategori (target) jadi angka\n",
    "encoder = LabelEncoder()\n",
    "target=encoder.fit_transform(target)\n",
    "target = keras.utils.to_categorical(target, 2)\n",
    "# split data\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data,target,test_size=0.2,random_state=1)"
   ],
   "id": "6c00d0ad7fa686a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# initiate",
   "id": "86532ac35da825ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "img_size=200",
   "id": "afbb3cbbb7b415eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# MobileNetV2\n",
    "base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "# InceptionV3\n",
    "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "# VGG16\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "# ResNet50\n",
    "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))"
   ],
   "id": "e4654df68a0dd8e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# mobilenet",
   "id": "c3e3332fba84e9b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def combined_metric(y_true, y_pred):\n",
    "  val_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "  val_acc = tf.keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "  return val_loss * (1 - val_acc)  # Lower values indicate better performance"
   ],
   "id": "fc025bec4ac9f4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"start : \"+str(datetime.datetime.now().time()))",
   "id": "effdc7393e3dd8e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# code 1\n",
    "# Freeze the base model agar bisa di compile\n",
    "base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model_mobilenet.trainable = False\n",
    "print(\"1\")\n",
    "model_mobilenet = base_model_mobilenet.output\n",
    "model_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\n",
    "model_mobilenet = Dense(128, activation='relu')(model_mobilenet)\n",
    "model_mobilenet = Dense(2, activation='softmax')(model_mobilenet)\n",
    "model = tf.keras.models.Model(inputs=base_model_mobilenet.input, outputs=model_mobilenet)\n",
    "\n",
    "print(\"2\")\n",
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "print(\"3\")\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', combined_metric])\n",
    "\n",
    "checkPoint = tf.keras.callbacks.ModelCheckpoint(filepath=chekpoints_path+\"/cp_mobilenetv2.keras\",verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_combined_metric', min_delta=0.00001, mode='min',restore_best_weights=True)\n",
    "\n",
    "print(\"4\")\n",
    "model.fit(xtrain2, ytrain2, epochs=32, validation_data=(xtest2, ytest2),callbacks=checkPoint)\n",
    "\n",
    "evaluation_results = model.evaluate(xtest2, ytest2)\n",
    "\n",
    "# Access the accuracy from the results (index 1 corresponds to accuracy)\n",
    "accuracy = evaluation_results[1]\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('loss: {}'.format(evaluation_results[0]))\n",
    "print('metriks: {}'.format(evaluation_results[2]))\n",
    "\n",
    "model.save(model_path+\"/model_mobilenetv2.keras\")"
   ],
   "id": "53fb1488697367f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"mobileNet done : \"+str(datetime.datetime.now().time()))\n",
   "id": "17002c45d7941b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# inception",
   "id": "59b3aea99e9ce3cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## tanpa transer learning",
   "id": "b92f8fd00491251e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## dengan transfer learning",
   "id": "902a5d1313052e05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_mobilenet=keras.models.load_model(model_path+\"model_mobilenetv2.keras\")",
   "id": "44783299b7fd0d85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# code test\n",
    "# Freeze the base model\n",
    "print(\"1\")\n",
    "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model_inception.trainable = False\n",
    "print(\"2\")\n",
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "print(\"a\")\n",
    "\n",
    "# Extract features using the pre-trained MobileNetV2 model\n",
    "# Remove the last layer from model_mobilenet to get 4D output\n",
    "model_mobilenet_notop = tf.keras.models.Model(inputs=model_mobilenet.input, outputs=model_mobilenet.layers[-2].output)\n",
    "features_train = model_mobilenet_notop.predict(xtrain2)\n",
    "features_test = model_mobilenet_notop.predict(xtest2)\n",
    "print(\"b\")\n",
    "\n",
    "# Build the InceptionV3 model on top of extracted features\n",
    "model_inception = Sequential()\n",
    "\n",
    "# Reshape features to 4D if they are flattened\n",
    "if features_train.ndim == 2:\n",
    "    features_train = features_train.reshape(features_train.shape[0], 1, 1, features_train.shape[1])\n",
    "    features_test = features_test.reshape(features_test.shape[0], 1, 1, features_test.shape[1])\n",
    "\n",
    "print(\"c\")\n",
    "\n",
    "model_inception.add(GlobalAveragePooling2D(input_shape=features_train.shape[1:]))  # Now features_train.shape[1:] should be 4D\n",
    "model_inception.add(Dense(128, activation='relu'))\n",
    "model_inception.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_inception.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', combined_metric])\n",
    "\n",
    "checkPoint = tf.keras.callbacks.ModelCheckpoint(filepath=chekpoints_path+\"/cp_inception_tf.keras\",verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_combined_metric', min_delta=0.00001, mode='min',restore_best_weights=True)\n",
    "print(\"d\")\n",
    "\n",
    "# Train the model\n",
    "model_inception.fit(features_train, ytrain2, epochs=32, validation_data=(features_test, ytest2), callbacks=checkPoint)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model_inception.evaluate(features_test, ytest2)\n",
    "\n",
    "# Access the accuracy from the results (index 1 corresponds to accuracy)\n",
    "accuracy = evaluation_results[1]\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('loss: {}'.format(evaluation_results[0]))\n",
    "print('metriks: {}'.format(evaluation_results[2]))\n",
    "\n",
    "model_inception.save(model_path+\"/model_inception_tf.keras\")"
   ],
   "id": "81e1d4c740c1c997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"inception 2 : \"+str(datetime.datetime.now().time()))\n",
   "id": "2e4d06da47c8d00b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# VGG",
   "id": "34ce826a2171608c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## transfer",
   "id": "a0d150a26843c946"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Freeze the base model\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model_vgg16.trainable = False\n",
    "\n",
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "\n",
    "# Extract features using the pre-trained MobileNetV2 model\n",
    "# Remove the last layer from model_mobilenet to get 4D output\n",
    "model_mobilenet_notop = tf.keras.models.Model(inputs=model_mobilenet.input, outputs=model_mobilenet.layers[-2].output)\n",
    "features_train = model_mobilenet_notop.predict(xtrain2)\n",
    "features_test = model_mobilenet_notop.predict(xtest2)\n",
    "\n",
    "# Build the VGG16 model on top of extracted features\n",
    "model_vgg16 = Sequential()\n",
    "\n",
    "# Reshape features to 4D if they are flattened\n",
    "if features_train.ndim == 2:\n",
    "    features_train = features_train.reshape(features_train.shape[0], 1, 1, features_train.shape[1])\n",
    "    features_test = features_test.reshape(features_test.shape[0], 1, 1, features_test.shape[1])\n",
    "\n",
    "model_vgg16.add(GlobalAveragePooling2D(input_shape=features_train.shape[1:]))  # Now features_train.shape[1:] should be 4D\n",
    "model_vgg16.add(Dense(128, activation='relu'))\n",
    "model_vgg16.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_vgg16.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', combined_metric])\n",
    "\n",
    "checkPoint = tf.keras.callbacks.ModelCheckpoint(filepath=chekpoints_path+\"/cp_vgg16_tf.keras\",verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_combined_metric', min_delta=0.00001, mode='min',restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_vgg16.fit(features_train, ytrain2, epochs=32, validation_data=(features_test, ytest2), callbacks=checkPoint)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model_vgg16.evaluate(features_test, ytest2)\n",
    "\n",
    "# Access the accuracy from the results (index 1 corresponds to accuracy)\n",
    "accuracy = evaluation_results[1]\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('loss: {}'.format(evaluation_results[0]))\n",
    "print('metriks: {}'.format(evaluation_results[2]))\n",
    "\n",
    "model_vgg16.save(model_path+\"/model_vgg16_tf.keras\")"
   ],
   "id": "6bd7facb994b9fcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ResNet",
   "id": "9fc6e3a71b1d3db2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## transfer\n",
   "id": "89943dc6c67c3505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# prompt: transfer learning resnet 50 from mobile net\n",
    "\n",
    "# Freeze the base model\n",
    "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model_resnet50.trainable = False\n",
    "\n",
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "\n",
    "# Extract features using the pre-trained MobileNetV2 model\n",
    "# Remove the last layer from model_mobilenet to get 4D output\n",
    "model_mobilenet_notop = tf.keras.models.Model(inputs=model_mobilenet.input, outputs=model_mobilenet.layers[-2].output)\n",
    "features_train = model_mobilenet_notop.predict(xtrain2)\n",
    "features_test = model_mobilenet_notop.predict(xtest2)\n",
    "\n",
    "# Build the ResNet50 model on top of extracted features\n",
    "model_resnet50 = Sequential()\n",
    "\n",
    "# Reshape features to 4D if they are flattened\n",
    "if features_train.ndim == 2:\n",
    "    features_train = features_train.reshape(features_train.shape[0], 1, 1, features_train.shape[1])\n",
    "    features_test = features_test.reshape(features_test.shape[0], 1, 1, features_test.shape[1])\n",
    "\n",
    "model_resnet50.add(GlobalAveragePooling2D(input_shape=features_train.shape[1:]))  # Now features_train.shape[1:] should be 4D\n",
    "model_resnet50.add(Dense(128, activation='relu'))\n",
    "model_resnet50.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_resnet50.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', combined_metric])\n",
    "\n",
    "checkPoint = tf.keras.callbacks.ModelCheckpoint(filepath=chekpoints_path+\"/cp_resnet50_tf.keras\",verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_combined_metric', min_delta=0.00001, mode='min',restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_resnet50.fit(features_train, ytrain2, epochs=32, validation_data=(features_test, ytest2), callbacks=checkPoint)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model_resnet50.evaluate(features_test, ytest2)\n",
    "\n",
    "# Access the accuracy from the results (index 1 corresponds to accuracy)\n",
    "accuracy = evaluation_results[1]\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('loss: {}'.format(evaluation_results[0]))\n",
    "print('metriks: {}'.format(evaluation_results[2]))\n",
    "\n",
    "model_resnet50.save(model_path+\"/model_resnet50_tf.keras\")"
   ],
   "id": "df4c263296847173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"end : \"+str(datetime.datetime.now().time()))",
   "id": "a10328d8aeb1f473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_resnet50 = tf.keras.models.load_model(\"Model CNN/no patience/model_resnet50_tf.keras\")\n",
    "model_mobilenet=tf.keras.models.load_model(\"Model CNN/no patience/model_mobilenetv2.keras\")\n",
    "model_inception=tf.keras.models.load_model(\"Model CNN/no patience/model_inception_tf.keras\")\n",
    "model_vgg=tf.keras.models.load_model(\"Model CNN/no patience/model_vgg16_tf.keras\")"
   ],
   "id": "5016eb4467dc1b92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:29:13.627280300Z",
     "start_time": "2024-09-10T05:08:46.761603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "model_mobilenet_notop = tf.keras.models.Model(inputs=model_mobilenet.input, outputs=model_mobilenet.layers[-2].output)\n",
    "features_train = model_mobilenet_notop.predict(xtrain2)\n",
    "features_test = model_mobilenet_notop.predict(xtest2)\n",
    "if features_train.ndim == 2:\n",
    "    features_train = features_train.reshape(features_train.shape[0], 1, 1, features_train.shape[1])\n",
    "    features_test = features_test.reshape(features_test.shape[0], 1, 1, features_test.shape[1])"
   ],
   "id": "9613a4220c10914c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1066/1066\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1527s\u001B[0m 1s/step\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m383s\u001B[0m 1s/step\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:29:13.628278300Z",
     "start_time": "2024-09-10T05:57:38.236037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss,acc=model_mobilenet.evaluate(xtest2, ytest2)\n",
    "print(\"mobilenet\")\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"vgg16\")\n",
    "loss,acc=model_vgg.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"inception\")\n",
    "loss,acc=model_inception.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"resnet\")\n",
    "loss,acc=model_resnet50.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)"
   ],
   "id": "ec360aa21cf31341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m395s\u001B[0m 1s/step - accuracy: 0.9947 - loss: 0.0326\n",
      "mobilenet\n",
      "loss:  0.03174535557627678\n",
      "acc:  0.9942501783370972\n",
      "\n",
      "vgg16\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 829us/step - accuracy: 0.9948 - loss: 0.1196\n",
      "loss:  0.12244947254657745\n",
      "acc:  0.9941328167915344\n",
      "\n",
      "inception\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 832us/step - accuracy: 0.9950 - loss: 0.1094\n",
      "loss:  0.1076526790857315\n",
      "acc:  0.9943675398826599\n",
      "\n",
      "resnet\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 821us/step - accuracy: 0.9952 - loss: 0.0992\n",
      "loss:  0.10059183090925217\n",
      "acc:  0.9946022033691406\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:29:13.628278300Z",
     "start_time": "2024-09-10T06:08:58.301897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_resnet50 = tf.keras.models.load_model(\"Model CNN/epoch 10/model_resnet50_tf.keras\")\n",
    "model_mobilenet=tf.keras.models.load_model(\"Model CNN/epoch 10/model_mobilenetv2.keras\")\n",
    "model_inception=tf.keras.models.load_model(\"Model CNN/epoch 10/model_inception_transfer.keras\")\n",
    "model_vgg=tf.keras.models.load_model(\"Model CNN/epoch 10/model_vgg16_tf.keras\")"
   ],
   "id": "8e33e072277547c6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:29:13.628278300Z",
     "start_time": "2024-09-10T06:09:57.856817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xtrain2 = np.array(xtrain.copy())\n",
    "xtest2 = np.array(xtest.copy())\n",
    "ytrain2 = np.array(ytrain.copy())\n",
    "ytest2 = np.array(ytest.copy())\n",
    "model_mobilenet_notop = tf.keras.models.Model(inputs=model_mobilenet.input, outputs=model_mobilenet.layers[-2].output)\n",
    "features_train = model_mobilenet_notop.predict(xtrain2)\n",
    "features_test = model_mobilenet_notop.predict(xtest2)\n",
    "if features_train.ndim == 2:\n",
    "    features_train = features_train.reshape(features_train.shape[0], 1, 1, features_train.shape[1])\n",
    "    features_test = features_test.reshape(features_test.shape[0], 1, 1, features_test.shape[1])"
   ],
   "id": "842dcf231f2bc823",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1066/1066\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1415s\u001B[0m 1s/step\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m369s\u001B[0m 1s/step\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T02:29:13.628278300Z",
     "start_time": "2024-09-10T06:40:04.126371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# epoch 10\n",
    "loss,acc=model_mobilenet.evaluate(xtest2, ytest2)\n",
    "print(\"mobilenet\")\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"vgg16\")\n",
    "loss,acc=model_vgg.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"inception\")\n",
    "loss,acc=model_inception.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)\n",
    "print(\"\")\n",
    "\n",
    "print(\"resnet\")\n",
    "loss,acc=model_resnet50.evaluate(features_test, ytest2)\n",
    "print(\"loss: \",loss)\n",
    "print(\"acc: \",acc)"
   ],
   "id": "6e0db211ff80cfce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m374s\u001B[0m 1s/step - accuracy: 0.9872 - loss: 0.0433\n",
      "mobilenet\n",
      "loss:  0.040294528007507324\n",
      "acc:  0.9872095584869385\n",
      "\n",
      "vgg16\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 742us/step - accuracy: 0.9944 - loss: 0.0217\n",
      "loss:  0.022837607190012932\n",
      "acc:  0.9936634302139282\n",
      "\n",
      "inception\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 724us/step - accuracy: 0.9936 - loss: 0.0433\n",
      "loss:  0.03844885155558586\n",
      "acc:  0.9926073551177979\n",
      "\n",
      "resnet\n",
      "\u001B[1m267/267\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 735us/step - accuracy: 0.9941 - loss: 0.0206\n",
      "loss:  0.022178806364536285\n",
      "acc:  0.9934287667274475\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
